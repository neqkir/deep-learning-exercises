{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFP_Issue.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCRfwBDJQgF4",
        "outputId": "b60f4f4f-ac25-48bb-c990-b70545256994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "      input  predict_1\n",
            "0  3.498475  12.239330\n",
            "1  2.134057   4.554200\n",
            "2  5.456111  29.769145\n",
            "3  0.263752   0.069565\n",
            "4  7.399465  54.752085\n",
            "1\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 10)                20        \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 2)                 22        \n",
            "                                                                 \n",
            " distribution_lambda_5 (Dist  ((None, 1),              0         \n",
            " ributionLambda)              (None, 1))                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 152\n",
            "Trainable params: 152\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 1s 2ms/step - loss: 242.7240\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 4.1590\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 1.5778\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 1.5973\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 1.0315\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 0.8027\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 0.5877\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 0.5011\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 1.2497\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 0.6612\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b789d30d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Predicting two outputs\n",
        "# described by a probability distribution (a mean and a standard deviation)\n",
        "# --> solution 1 : two final Dense layers\n",
        "# https://stackoverflow.com/questions/71300786/tensorflow-probability-want-nn-to-output-multiple-distributions\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "tf.__version__\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "df['input'] = np.random.uniform(-10.0, 10.0, 5000)\n",
        "\n",
        "# Simple rules:\n",
        "#   If input is positive:\n",
        "#     pos_points = input * input\n",
        "#     neg_points = -0.5 * input\n",
        "#\n",
        "#   If input is negative:\n",
        "#     pos_points = -0.5 * input\n",
        "#     neg_points = -input * input\n",
        "\n",
        "df['predict_1'] = df['input'].apply(lambda x: x*x if x > 0 else x * -0.5)\n",
        "# df['predict_2'] = df['input'].apply(lambda x: x*x*-1 if x < 0 else -x * 0.5)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "target = pd.concat([df.pop(x) for x in ['predict_1']], axis=1)\n",
        "\n",
        "tfd = tfp.distributions\n",
        "\n",
        "print(len(df.columns))\n",
        "\n",
        "# Build a simple model to go from input to the two outputs\n",
        "def get_df_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=[len(df.columns),], activation='relu'), # Should only be one input, so [1,]\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(2 * len(target.columns)), # there is 1 value we're predicting, we want a mean + standard deviation, so TWO outputs\n",
        "    tfp.layers.DistributionLambda(\n",
        "      lambda t: tfd.Normal(loc=t[..., :1],\n",
        "                           scale=1e-3 + tf.math.softplus(0.05 * t[...,1:]))\n",
        "    )\n",
        "  ])\n",
        "\n",
        "  negloglik = lambda y, rv_y: -rv_y.log_prob(y)\n",
        "\n",
        "  model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=negloglik)\n",
        "  return model\n",
        "\n",
        "model = get_df_model()\n",
        "model.summary()\n",
        "model.fit(df, target, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test results:\n",
        "yhat = model(df.to_numpy(dtype=np.float32))\n",
        "\n",
        "print(df.head(1))\n",
        "print(target.head(1))\n",
        "\n",
        "print(\"----- Predictions:\")\n",
        "print(\"mean\", yhat.mean()[0])\n",
        "print(\"stddev\", yhat.stddev()[0])"
      ],
      "metadata": {
        "id": "4UomdA7FQhYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Now, lets try to predict two independent distributions ####\n",
        "# Simple rules:\n",
        "#   If input is positive:\n",
        "#     pos_points = input * input\n",
        "#     neg_points = -0.5 * input\n",
        "#\n",
        "#   If input is negative:\n",
        "#     pos_points = -0.5 * input\n",
        "#     neg_points = -input * input\n",
        "\n",
        "print('start')\n",
        "df['predict_1'] = df['input'].apply(lambda x: x*x if x > 0 else x * -0.5)\n",
        "df['predict_2'] = df['input'].apply(lambda x: x*x*-1 if x < 0 else -x * 0.5)\n",
        "\n",
        "print('df.head')\n",
        "print(df.head())\n",
        "\n",
        "target = pd.concat([df.pop(x) for x in ['predict_1', 'predict_2']], axis=1)\n",
        "tfd = tfp.distributions"
      ],
      "metadata": {
        "id": "2wH9BG5xhWnA",
        "outputId": "145855a0-cab9-42f0-adc3-880a9fa94bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "df.head\n",
            "      input  predict_1  predict_2\n",
            "0  3.498475  12.239330  -1.749238\n",
            "1  2.134057   4.554200  -1.067029\n",
            "2  5.456111  29.769145  -2.728055\n",
            "3  0.263752   0.069565  -0.131876\n",
            "4  7.399465  54.752085  -3.699733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfd = tfp.distributions\n",
        "sample_layer = tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t[..., :1],\n",
        "                           scale=1e-3 + tf.math.softplus(0.05 * t[...,1:])))\n",
        "def get_df_model():\n",
        "  inputs = tf.keras.layers.Input(shape=[len(df.columns),])\n",
        "  x = tf.keras.layers.Dense(10, activation='relu')(inputs)\n",
        "  x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
        "  outputs1 = tf.keras.layers.Dense(len(target.columns))(x)\n",
        "  outputs2 = tf.keras.layers.Dense(len(target.columns))(x) # there are 2 outputs, so we want a mean + standard deviation for EACH of the outputs\n",
        "    \n",
        "  outputs1 = sample_layer(outputs1)\n",
        "  outputs2 = sample_layer(outputs2)\n",
        "  model = tf.keras.Model(inputs, [outputs1, outputs2])\n",
        "\n",
        "  negloglik = lambda y, rv_y: -rv_y.log_prob(y)\n",
        "\n",
        "  model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=negloglik)\n",
        "  return model"
      ],
      "metadata": {
        "id": "ELpAUJPtkUcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_df_model()\n",
        "model.summary()\n",
        "model.fit(df, target, epochs=10)"
      ],
      "metadata": {
        "id": "Ou6-E1UVRMlk",
        "outputId": "2caf5430-c27f-4b94-a052-daa7cb81e98d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_51 (Dense)               (None, 10)           20          ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_52 (Dense)               (None, 10)           110         ['dense_51[0][0]']               \n",
            "                                                                                                  \n",
            " dense_53 (Dense)               (None, 4)            44          ['dense_52[0][0]']               \n",
            "                                                                                                  \n",
            " tf.split (TFOpLambda)          [(None, 2),          0           ['dense_53[0][0]']               \n",
            "                                 (None, 2)]                                                       \n",
            "                                                                                                  \n",
            " distribution_lambda_14 (Distri  ((None, 1),         0           ['tf.split[0][0]',               \n",
            " butionLambda)                   (None, 1))                       'tf.split[0][1]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 174\n",
            "Trainable params: 174\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 1s 2ms/step - loss: 430.7491 - distribution_lambda_14_loss: 178.6711 - distribution_lambda_14_1_loss: 252.0782\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 19.5993 - distribution_lambda_14_loss: 8.3207 - distribution_lambda_14_1_loss: 11.2786\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 12.8901 - distribution_lambda_14_loss: 5.7957 - distribution_lambda_14_1_loss: 7.0944\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 10.7484 - distribution_lambda_14_loss: 5.0028 - distribution_lambda_14_1_loss: 5.7457\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 9.7677 - distribution_lambda_14_loss: 4.6466 - distribution_lambda_14_1_loss: 5.1211\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 9.2357 - distribution_lambda_14_loss: 4.4564 - distribution_lambda_14_1_loss: 4.7792\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 8.9214 - distribution_lambda_14_loss: 4.3462 - distribution_lambda_14_1_loss: 4.5752\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 8.7235 - distribution_lambda_14_loss: 4.2782 - distribution_lambda_14_1_loss: 4.4453\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 8.5895 - distribution_lambda_14_loss: 4.2330 - distribution_lambda_14_1_loss: 4.3565\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 8.4986 - distribution_lambda_14_loss: 4.2031 - distribution_lambda_14_1_loss: 4.2955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b71ec8790>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}